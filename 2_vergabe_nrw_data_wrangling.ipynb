{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergabe NRW Data Wrangling / creating csv data_nrw_clean\n",
    "\n",
    "### When this data was collected?\n",
    "07 /01/2021  , see Vergabe NRW CSV file\n",
    "\n",
    "### What does this script do?\n",
    "This script analizes how what data is available in Vergabe NRW. Its intention is to search for vulnerabilities, and raise up questions about the codebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Defining the problem: What we want to see with this data?\n",
    "    \n",
    "During almost two years, the Federal and regional governments in Germany needed to aqquire a series of things to deal with COVID-19 pandemics. Due to factors such as lack of vendors, scarcity of material, urgency of purchesing among others, it is expected that many of these purchases are expected to have been made under extraordinary arrangements, involving exclusion from bidding, among others. But should all the purchases be made in this regime.\n",
    "\n",
    "**We want to discover if there is red flags for mismanagement in COVID-19 measures by the government of Nordrhein-Westfallen in Germany.** To do that, we need to answer the following questions:\n",
    "\n",
    "> 1. Are all the purchases regarding COVID-19 available ?\n",
    "> 2. How many purchases were made on an extraordinary basis (no bidding, direct negotiation with seller, etc) ?\n",
    "> 3. When these purchases were made?\n",
    "> 4. By the time of extraordinary purchases, was there actually a lack of vendors of urgency of for this purchase?\n",
    "\n",
    "And how can we beggin to answer those questions?\n",
    "\n",
    "1. Are all the purchases regarding COVID-19 available ?\n",
    "    - 1.1 Look at CPV Codes\n",
    "    - 1.2 Compare the purchases made it here with external databases (there is another Vergabe portal)\n",
    "    - 1.3 Validate the data with local data (for example, the city of Köln, which might have their own transparency portal)\n",
    "    - 1.4 Validate the data of a municipality with a Fredom of Information Request\n",
    "<br><br>\n",
    "2. How many purchases were made on an extraordinary basis (no bidding, direct negotiation with seller, etc) ?\n",
    "    - 2.1 See if the data from Vergabe NRW has information about the bidding format and type of contract\n",
    "<br><br>    \n",
    "3. When these purchases were made?\n",
    "    - 3.1 See if the data from Vergabe NRW has information about the data of purchase \n",
    "    - 3.2 See if the data from Vergabe NRW has information about the date of contracts\n",
    "<br><br>\n",
    "4. By the time of extraordinary purchases, was there actually a lack of vendors of urgency of for this purchase?\n",
    "    - 4.1 Cross the date information with COVID-19 cases in Germany\n",
    "    - 4.2 Cross the date information with Hospital Capacity\n",
    "    - 4.3 See if we find intresting information, milestones or similar information in news articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Exploring the data\n",
    "\n",
    "In this specific notebook I'll see the state of art of the data collected from Vergabe NRW and see what problems does it has. The following will be verified:\n",
    "\n",
    "\n",
    "\n",
    "1. Is there duplicates?\n",
    "2. Is there missing data?\n",
    "    - what is this missing data doing in my db?\n",
    "    \n",
    "3. Is there encoding problem?\n",
    "4. Do the cities have always the same name? Or do they have different writings?\n",
    "5. Is there any information regarding costs? Are the derzeitige Werten (valores correntes)?\n",
    "6. What each collumn means?\n",
    "7. What each observation is?\n",
    "8. Which of the above questions (Step 1) can we answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib \n",
    "import numpy as np\n",
    "import janitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not belong to the analysis, I'm just creating a function to help me lates:\n",
    "\n",
    "def glimpse(df, maxvals=10, maxlen=110):\n",
    "    print('Shape: ', df.shape)\n",
    "    \n",
    "    def pad(y):\n",
    "        max_len = max([len(x) for x in y])\n",
    "        return [x.ljust(max_len) for x in y]\n",
    "    \n",
    "    # Column Name\n",
    "    toprnt = pad(df.columns.tolist())\n",
    "    \n",
    "    # Column Type\n",
    "    toprnt = pad([toprnt[i] + ' ' + str(df.iloc[:,i].dtype) for i in range(df.shape[1])])\n",
    "    \n",
    "    # Num NAs\n",
    "    num_nas = [df.iloc[:,i].isnull().sum() for i in range(df.shape[1])]\n",
    "    num_nas_ratio = [int(round(x*100/df.shape[0])) for x in num_nas]\n",
    "    num_nas_str = [str(x) + ' (' + str(y) + '%)' for x,y in zip(num_nas, num_nas_ratio)]\n",
    "    max_len = max([len(x) for x in num_nas_str])\n",
    "    num_nas_str = [x.rjust(max_len) for x in num_nas_str]\n",
    "    toprnt = [x + ' ' + y + ' NAs' for x,y in zip(toprnt, num_nas_str)]\n",
    "    \n",
    "    # Separator\n",
    "    toprnt = [x + ' : ' for x in toprnt]\n",
    "    \n",
    "    # Values\n",
    "    toprnt = [toprnt[i] + ', '.join([str(y) for y in df.iloc[:min([maxvals,df.shape[0]]), i]]) for i in range(df.shape[1])]\n",
    "    \n",
    "    # Trim to maxlen\n",
    "    toprnt = [x[:min(maxlen, len(x))] for x in toprnt]\n",
    "    \n",
    "    for x in toprnt:\n",
    "        print(x)\n",
    "        \n",
    "\n",
    "####sec function:\n",
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing scraped data\n",
    "data_nrw = pd.read_csv(\"df_vergabe_nrw_jan2021.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already some problems in importing this data: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>result_id</th>\n",
       "      <th>result_title</th>\n",
       "      <th>result_description</th>\n",
       "      <th>result_procedure_type</th>\n",
       "      <th>result_order_type</th>\n",
       "      <th>result_publication_date</th>\n",
       "      <th>...</th>\n",
       "      <th>result_buyer_postal_code</th>\n",
       "      <th>result_seller_name</th>\n",
       "      <th>result_seller_town</th>\n",
       "      <th>result_seller_country</th>\n",
       "      <th>result_geo_lon</th>\n",
       "      <th>result_geo_lat</th>\n",
       "      <th>result_value</th>\n",
       "      <th>result_created_at</th>\n",
       "      <th>result_updated_at</th>\n",
       "      <th>result_buyer_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CXPNY42D0ZS</td>\n",
       "      <td>2022-01-04T23:00:18.455Z</td>\n",
       "      <td>2022-01-06T23:00:14.633Z</td>\n",
       "      <td>CXPNY42D0ZS</td>\n",
       "      <td>Öffnen/Verschließen von Türen/Toren aller Art ...</td>\n",
       "      <td>['Schüsseldienste kamen im Kalenderjahr 2021 z...</td>\n",
       "      <td>Öffentliche Ausschreibung</td>\n",
       "      <td>UVGO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>44139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.46023</td>\n",
       "      <td>51.49958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-04T23:00:18.455Z</td>\n",
       "      <td>2022-01-06T23:00:14.633Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CXPNY42D474</td>\n",
       "      <td>2021-05-26T22:20:10.194Z</td>\n",
       "      <td>2021-06-08T22:19:38.411Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-26T22:20:10.194Z</td>\n",
       "      <td>2021-06-08T22:19:38.411Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CXPNY42D4QL</td>\n",
       "      <td>2021-05-26T22:18:23.840Z</td>\n",
       "      <td>2021-05-31T22:17:09.010Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-26T22:18:23.840Z</td>\n",
       "      <td>2021-05-31T22:17:09.010Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CXPNY42DR40</td>\n",
       "      <td>2020-05-11T00:12:51.144Z</td>\n",
       "      <td>2020-06-26T23:21:14.223Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-11T00:12:51.144Z</td>\n",
       "      <td>2020-06-26T23:21:14.223Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CXPNY42DRDN</td>\n",
       "      <td>2020-04-20T22:14:01.166Z</td>\n",
       "      <td>2020-05-19T00:33:44.632Z</td>\n",
       "      <td>CXPNY42DRDN</td>\n",
       "      <td>Videobeobachtung Dortmund Münsterstraße</td>\n",
       "      <td>['Software, Hardware, Installations- und Monta...</td>\n",
       "      <td>Öffentliche Ausschreibung</td>\n",
       "      <td>UVGO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>44139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.46023</td>\n",
       "      <td>51.49958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-20T22:14:01.166Z</td>\n",
       "      <td>2020-05-19T00:33:44.632Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          _id                created_at  \\\n",
       "0           0  CXPNY42D0ZS  2022-01-04T23:00:18.455Z   \n",
       "1           1  CXPNY42D474  2021-05-26T22:20:10.194Z   \n",
       "2           2  CXPNY42D4QL  2021-05-26T22:18:23.840Z   \n",
       "3           3  CXPNY42DR40  2020-05-11T00:12:51.144Z   \n",
       "4           4  CXPNY42DRDN  2020-04-20T22:14:01.166Z   \n",
       "\n",
       "                 updated_at    result_id  \\\n",
       "0  2022-01-06T23:00:14.633Z  CXPNY42D0ZS   \n",
       "1  2021-06-08T22:19:38.411Z          NaN   \n",
       "2  2021-05-31T22:17:09.010Z          NaN   \n",
       "3  2020-06-26T23:21:14.223Z          NaN   \n",
       "4  2020-05-19T00:33:44.632Z  CXPNY42DRDN   \n",
       "\n",
       "                                        result_title  \\\n",
       "0  Öffnen/Verschließen von Türen/Toren aller Art ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4            Videobeobachtung Dortmund Münsterstraße   \n",
       "\n",
       "                                  result_description  \\\n",
       "0  ['Schüsseldienste kamen im Kalenderjahr 2021 z...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  ['Software, Hardware, Installations- und Monta...   \n",
       "\n",
       "       result_procedure_type result_order_type result_publication_date  ...  \\\n",
       "0  Öffentliche Ausschreibung              UVGO                     NaN  ...   \n",
       "1                        NaN               NaN                     NaN  ...   \n",
       "2                        NaN               NaN                     NaN  ...   \n",
       "3                        NaN               NaN                     NaN  ...   \n",
       "4  Öffentliche Ausschreibung              UVGO                     NaN  ...   \n",
       "\n",
       "  result_buyer_postal_code result_seller_name result_seller_town  \\\n",
       "0                    44139                NaN                NaN   \n",
       "1                      NaN                NaN                NaN   \n",
       "2                      NaN                NaN                NaN   \n",
       "3                      NaN                NaN                NaN   \n",
       "4                    44139                NaN                NaN   \n",
       "\n",
       "  result_seller_country result_geo_lon result_geo_lat result_value  \\\n",
       "0                   NaN        7.46023       51.49958          NaN   \n",
       "1                   NaN            NaN            NaN          NaN   \n",
       "2                   NaN            NaN            NaN          NaN   \n",
       "3                   NaN            NaN            NaN          NaN   \n",
       "4                   NaN        7.46023       51.49958          NaN   \n",
       "\n",
       "          result_created_at         result_updated_at  result_buyer_country  \n",
       "0  2022-01-04T23:00:18.455Z  2022-01-06T23:00:14.633Z                   NaN  \n",
       "1  2021-05-26T22:20:10.194Z  2021-06-08T22:19:38.411Z                   NaN  \n",
       "2  2021-05-26T22:18:23.840Z  2021-05-31T22:17:09.010Z                   NaN  \n",
       "3  2020-05-11T00:12:51.144Z  2020-06-26T23:21:14.223Z                   NaN  \n",
       "4  2020-04-20T22:14:01.166Z  2020-05-19T00:33:44.632Z                   NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando as cinco primeiras colunas\n",
    "data_nrw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What period is this data about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min created_at 2019-12-17T14:29:56.168Z \n",
      " max created_at 2022-01-07T02:11:51.498Z \n",
      " min updated_at 2019-12-17T14:43:09.787Z \n",
      " max updated_at 2022-01-07T02:12:23.505Z\n"
     ]
    }
   ],
   "source": [
    "print(\"min created_at\", min(data_nrw.created_at), \"\\n max created_at\",max(data_nrw.created_at),\n",
    "      \"\\n min updated_at\", min(data_nrw.updated_at), \"\\n max updated_at\", max(data_nrw.updated_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (47502, 24)\n",
      "Unnamed: 0               int64        0 (0%) NAs : 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
      "_id                      object       0 (0%) NAs : CXPNY42D0ZS, CXPNY42D474, CXPNY42D4QL, CXPNY42DR40, CXPNY42\n",
      "created_at               object       0 (0%) NAs : 2022-01-04T23:00:18.455Z, 2021-05-26T22:20:10.194Z, 2021-05\n",
      "updated_at               object       0 (0%) NAs : 2022-01-06T23:00:14.633Z, 2021-06-08T22:19:38.411Z, 2021-05\n",
      "result_id                object  10930 (23%) NAs : CXPNY42D0ZS, nan, nan, nan, CXPNY42DRDN, nan, CXPNY42YT80, \n",
      "result_title             object  11462 (24%) NAs : Öffnen/Verschließen von Türen/Toren aller Art im Wege der E\n",
      "result_description       object  10930 (23%) NAs : ['Schüsseldienste kamen im Kalenderjahr 2021 zu insgesamt 4\n",
      "result_procedure_type    object  13554 (29%) NAs : Öffentliche Ausschreibung, nan, nan, nan, Öffentliche Aussc\n",
      "result_order_type        object  13554 (29%) NAs : UVGO, nan, nan, nan, UVGO, nan, OTHER, nan, UVGO, UVGO\n",
      "result_publication_date  object  36823 (78%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_cpv_codes         object  10930 (23%) NAs : ['75131000-3', '75240000-0'], nan, nan, nan, ['75131000-3']\n",
      "result_buyer_name        object  10930 (23%) NAs : Polizeipräsidium Dortmund - ZA 13.1 - Zentrale Vergabestell\n",
      "result_buyer_address     object  10939 (23%) NAs : Markgrafenstraße 102, nan, nan, nan, Markgrafebstraße 102, \n",
      "result_buyer_town        object  10930 (23%) NAs : Dortmund, nan, nan, nan, Dortmund, nan, Dortmund, Dortmund,\n",
      "result_buyer_postal_code object  10936 (23%) NAs : 44139, nan, nan, nan, 44139, nan, 44139, 44139, 44608, 4460\n",
      "result_seller_name       object  46042 (97%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_seller_town       object  46042 (97%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_seller_country    object  46042 (97%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_geo_lon           float64 10930 (23%) NAs : 7.46023, nan, nan, nan, 7.46023, nan, 7.46023, 7.46023, 8.0\n",
      "result_geo_lat           float64 10930 (23%) NAs : 51.49958, nan, nan, nan, 51.49958, nan, 51.49958, 51.49958,\n",
      "result_value             float64 46066 (97%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_created_at        object       0 (0%) NAs : 2022-01-04T23:00:18.455Z, 2021-05-26T22:20:10.194Z, 2021-05\n",
      "result_updated_at        object       0 (0%) NAs : 2022-01-06T23:00:14.633Z, 2021-06-08T22:19:38.411Z, 2021-05\n",
      "result_buyer_country     object  44878 (94%) NAs : nan, nan, nan, nan, nan, nan, nan, DE, nan, nan\n"
     ]
    }
   ],
   "source": [
    "glimpse(data_nrw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47502, 24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Olhando qtde de linhas e colunas do meu df\n",
    "data_nrw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo duplicatas:\n",
    "\n",
    "data_nrw = data_nrw.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have any duplicates, it is not due to scraping, because the number of hits specified in the API and our final DB lenght is the same (47502) - see file '1. Vergabe NRW CSV file' - so we are cheking now if there are any duplicates in the original database. We are here considering duplicates when two lines (two inputs) are 100% equal. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47502, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nrw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No complete duplicates.\n",
    "Now we need to verify if we have any ID duplicated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See if we have duplicated ID:\n",
    "\n",
    "id_test = data_nrw.groupby(by = '_id').agg({'_id':['count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47502, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no repetead IDs.\n",
    "Now we need to see if the `result_id` is always equal to the `_id` . I already know that the main answer is no, since I have NaNs in `result_id` and I don't have them in `_id`, so I'll first drop the NaN in `result_id` and then check if the Ids might be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data_nrw\n",
    "x = x[x['result_id'].notna()]\n",
    "\n",
    "x.isnull().sum() #we do not have empty columns in result_id\n",
    "\n",
    "#See if they are the same\n",
    "x['_id'].equals(x['result_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer: We do not have duplicate entries** \n",
    "<br><br>\n",
    "### 2. Is there missing data?\n",
    "\n",
    "As we saw above, we do have both NaN data and empty Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing observations without excluding any data (original Dataset)**\n",
    "\n",
    "- The information missing the most is about the seller: te columns `result_seller_name`, `result_seller_town`, `result_seller_country`, `result_geo_lon` and `result_value` have all 97% of missing data.<br><br>\n",
    "- The columns `result_buyer_country`comes in seccond place with 94% of missing data. A possibility for it is that maybe all purchases are made in Germany. Need to dig into this information later.<br><br>\n",
    "- The column `result_publication_date` has 78% of the missing data. <br><br>\n",
    "- The columns `result_id`, `result_title`, `result_description`, `result_procedure_type`, `result_order_type`, `result_cpv_codes`, `result_buyer_name`, `result_buyer_address`, `result_buyer_town`, `result_buyer_postal_code`, `result_geo_lon` and `result_geo_lat` have from 23% to 29% of missing data.\n",
    "\n",
    "However, if we consider that the valid bidinds are the ones where `result_id`!= NaN, then we have the following scenario:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (36572, 24)\n",
      "Unnamed: 0               int64        0 (0%) NAs : 0, 4, 6, 7, 8, 9, 10, 11, 12, 13\n",
      "_id                      object       0 (0%) NAs : CXPNY42D0ZS, CXPNY42DRDN, CXPNY42YT80, CXPNY42YWAX, CXPNY43\n",
      "created_at               object       0 (0%) NAs : 2022-01-04T23:00:18.455Z, 2020-04-20T22:14:01.166Z, 2019-12\n",
      "updated_at               object       0 (0%) NAs : 2022-01-06T23:00:14.633Z, 2020-05-19T00:33:44.632Z, 2020-01\n",
      "result_id                object       0 (0%) NAs : CXPNY42D0ZS, CXPNY42DRDN, CXPNY42YT80, CXPNY42YWAX, CXPNY43\n",
      "result_title             object     532 (1%) NAs : Öffnen/Verschließen von Türen/Toren aller Art im Wege der E\n",
      "result_description       object       0 (0%) NAs : ['Schüsseldienste kamen im Kalenderjahr 2021 zu insgesamt 4\n",
      "result_procedure_type    object    2624 (7%) NAs : Öffentliche Ausschreibung, Öffentliche Ausschreibung, Öffen\n",
      "result_order_type        object    2624 (7%) NAs : UVGO, UVGO, OTHER, nan, UVGO, UVGO, UVGO, UVGO, UVGO, UVGO\n",
      "result_publication_date  object  25893 (71%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_cpv_codes         object       0 (0%) NAs : ['75131000-3', '75240000-0'], ['75131000-3'], ['55512000-2'\n",
      "result_buyer_name        object       0 (0%) NAs : Polizeipräsidium Dortmund - ZA 13.1 - Zentrale Vergabestell\n",
      "result_buyer_address     object       9 (0%) NAs : Markgrafenstraße 102, Markgrafebstraße 102, Markgrafenstraß\n",
      "result_buyer_town        object       0 (0%) NAs : Dortmund, Dortmund, Dortmund, Dortmund, Herne, Herne, Herne\n",
      "result_buyer_postal_code object       6 (0%) NAs : 44139, 44139, 44139, 44139, 44608, 44608, 44608, 44608, 446\n",
      "result_seller_name       object  35112 (96%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_seller_town       object  35112 (96%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_seller_country    object  35112 (96%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_geo_lon           float64      0 (0%) NAs : 7.46023, 7.46023, 7.46023, 7.46023, 8.0583, 8.0583, 8.0583,\n",
      "result_geo_lat           float64      0 (0%) NAs : 51.49958, 51.49958, 51.49958, 51.49958, 48.2167, 48.2167, 4\n",
      "result_value             float64 35136 (96%) NAs : nan, nan, nan, nan, nan, nan, nan, nan, nan, nan\n",
      "result_created_at        object       0 (0%) NAs : 2022-01-04T23:00:18.455Z, 2020-04-20T22:14:01.166Z, 2019-12\n",
      "result_updated_at        object       0 (0%) NAs : 2022-01-06T23:00:14.633Z, 2020-05-19T00:33:44.632Z, 2020-01\n",
      "result_buyer_country     object  33948 (93%) NAs : nan, nan, nan, DE, nan, nan, nan, nan, nan, nan\n"
     ]
    }
   ],
   "source": [
    "y = data_nrw\n",
    "y = y[y['result_id'].notna()]\n",
    "\n",
    "glimpse(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing observations whithin valid result_id:**\n",
    "\n",
    "- 96% of missing data in columns `result_seller_name`, `result_seller_town`, `result_seller_country`, `result_value`, and 93% in `result_buyer_country` <br><br>\n",
    "- 71% of missing data in column `result_publication_date`<br><br>\n",
    "- 7% of missing data in columns `result_procedure_type` and `result_order_type` <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we will create a **new working dataframe with which we will work up now:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nrw_valid_ids = y\n",
    "\n",
    "#Exportando em CSV\n",
    "data_nrw_valid_ids.to_csv(r'data_nrw_valid_ids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Is there any encoding problem? / 4. Do the cities have always the same name? Or do they have different writings?\n",
    "\n",
    "We have two ways to solve this: lat lon or city name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the city names to see how many unique values do we actually have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to clean german names:\n",
    "\n",
    "def clean_german(df, x):\n",
    "    return (\n",
    "        df\n",
    "        .replace({x: {'\\W': ' '}}, regex = True)\n",
    "        .replace({x: {'ä': 'ae', 'ö': 'oe', 'ü': 'ue', 'β': 'ss'}},  regex = True)\n",
    "        .replace({x: {'\\s{2,}': ''}}) #more than one whitespace\n",
    "        .replace({x: {'^\\s+': ''}})   #whitespace at the beggining\n",
    "        .replace({x: {'\\s+$': ''}})   #whitespace at the end\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-d1a43492640d>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_nrw_clean['clean_town'] = data_nrw_clean['result_buyer_town'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "#creating a new column with cleaned and fixed names:\n",
    "\n",
    "data_nrw_clean = data_nrw_valid_ids\n",
    "\n",
    "# Cria nova coluna \"clean buyer town\" e tranforma em lowecase\n",
    "data_nrw_clean['clean_town'] = data_nrw_clean['result_buyer_town'].str.lower()\n",
    "\n",
    "data_nrw_clean = clean_german(data_nrw_clean, 'clean_town')\n",
    "\n",
    "#other required replacements:\n",
    "data_nrw_clean = data_nrw_clean.replace({'clean_town': {'schleiden / 53937' : 'schleiden', '59192' :  'bergkamen', \n",
    "                                             '50259 pulheim' : 'pulheim',\n",
    "                                             'stadt pulheim' : 'pulheim',\n",
    "                                             'euv stadtbetrieb castrop rauxel aoer' : 'castrop rauxel',\n",
    "                                              'schleiden   53937': 'schleiden',\n",
    "                                              'gronau  westf  ': 'gronau'}}, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dortmund', 'herne', 'duesseldorf', 'essen', 'koeln', 'bonn',\n",
       "       'gummersbach', 'aachen', 'moenchengladbach', 'soest', 'bochum',\n",
       "       'schwelm', 'wuppertal', 'gelsenkirchen', 'siegen', 'siegburg',\n",
       "       'sankt augustin', 'paderborn', 'lemgo', 'ratingen', 'krefeld',\n",
       "       'schwerte', 'duisburg', 'hamm', 'muenster', 'steinfurt', 'werl',\n",
       "       'wesel', 'hagen', 'castrop rauxel', 'meschede', 'olpe',\n",
       "       'warburg scherfede', 'huerth', 'horn bad meinberg', 'detmold',\n",
       "       'willich', 'emmerich am rhein', 'oberhausen', 'dueren', 'monschau',\n",
       "       'heinsberg', 'selm', 'herford', 'billerbeck', 'rosendahl',\n",
       "       'hilchenbach', 'iserlohn', 'attendorn', 'froendenberg',\n",
       "       'remscheid', 'euskirchen', 'geldern', 'bielefeld', 'juelich',\n",
       "       'bergisch gladbach', 'hattingen', 'kerpen', 'recklinghausen',\n",
       "       'arnsberg', 'minden', 'coesfeld', 'osnabrueck', 'dillenburg',\n",
       "       'netphen', 'leverkusen', 'berlin', 'werne', 'unna', 'boenen',\n",
       "       'holzwickede', 'schhwelm', 'froendenberg ruhr', 'witten', 'luenen',\n",
       "       'heiden', 'schermbeck', 'datteln', 'waltrop', 'kamen',\n",
       "       'oer erkenschwick', 'dorsten', 'bergkamen', 'haltern am see',\n",
       "       'nuembrecht', 'moers', 'hilden', 'rheinbach', 'frechen',\n",
       "       'bergsich gladbach', 'kaarst', 'kuerten', 'neunkirchen seelscheid',\n",
       "       'bergheim', 'bergneustadt', 'hennef', 'bad honnef', 'marienheide',\n",
       "       'hueckeswagen', 'bornheim', 'ruppichteroth', 'nettetal',\n",
       "       'langenfeld', 'erftstadt', 'morsbach', 'leichlingen',\n",
       "       'wachtendonk', 'rheurdt', 'windeck', 'meckenheim', 'solingen',\n",
       "       'burscheid', 'niederkassel', 'troisdorf', 'swisttal',\n",
       "       'troisdorf sieglar', 'swisttal miel', 'korschenbroich',\n",
       "       'heiligenhaus', 'monheim am rhein', 'bruehl', 'bruehl ost',\n",
       "       'lohmar', 'bielefdeld', 'mettingen', 'vreden', 'wettringen',\n",
       "       'ascheberg', 'hoevelhof', 'ennigerloh', 'ahlen', 'luedenscheid',\n",
       "       'telgte', 'beckum', 'wadersloh', 'everswinkel', 'meinerzhagen',\n",
       "       'plettenberg', 'herscheid', 'buende', 'warendorf', 'nottuln',\n",
       "       'borken', 'rhede', 'balve', 'olsberg', 'velen', 'greven', 'halver',\n",
       "       'brilon', 'werdohl', 'stadtlohn', 'emsdetten', 'ahaus',\n",
       "       'ibbenbueren', 'gronau', 'isselburg', 'delbrueck westenholz',\n",
       "       'delbrueck', 'lengerich', 'suedlohn', 'kierspe', 'saerbeck',\n",
       "       'metelen', 'lienen', 'westerkappeln', 'horstmar', 'recke',\n",
       "       'neuenkirchen', 'hoerstel', 'sundern', 'oelde', 'bocholt',\n",
       "       'borgentreich', 'langerwehe', 'erkelenz', 'weilerswist',\n",
       "       'niederzier', 'heimbach', 'merzenich', 'noervenich', 'selfkant',\n",
       "       'wuerselen', 'bad muenstereifel', 'stolberg', 'stolbeerg',\n",
       "       'kreuzau', 'nettersheim', 'nettersheim zingsheim', 'gangelt',\n",
       "       'waldfeucht', 'blankenheim', 'kall', 'zuelpich', 'dahlem',\n",
       "       'schleiden', 'mechernich', 'alsdorf', 'baesweiler', 'eschweiler',\n",
       "       'wassenberg', 'titz', 'geilenkirchen', 'uebach palenberg',\n",
       "       'herzogenrath', 'linnich', 'simmerath', 'neuss',\n",
       "       'muelheim an der ruhr', 'bottrop', 'rheine', 'hemer', 'lippstadt',\n",
       "       'wesseling', 'kleve', 'schmallenberg', 'hueckelhoven', 'roesrath',\n",
       "       'marl', 'viersen', 'mettmann', 'eitorf', 'bad driburg',\n",
       "       'wuelfrath', 'wipperfuerth', 'radevormwald', 'pulheim', 'erkrath'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nrw_clean.clean_town.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now I need to see in the clean Data Frame which municipalities are not mentioned:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have here a first problem, since according to wikipedia NRW has 396 Städten. So some municipalities are not listed here. Let's continuing checking the funny characters and then we will see which municipalities are missing and which are here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openning oficial names from  cities in NRW:\n",
    "stadt_nrw_oficial = pd.read_csv(\"georef-germany-gemeinde.csv\", sep=';').clean_names()\n",
    "\n",
    "#cleaning names:\n",
    "\n",
    "stadt_nrw_oficial['clean_town'] = stadt_nrw_oficial['gemeinde_name_short_'].str.lower()\n",
    "\n",
    "stadt_nrw_oficial = clean_german(stadt_nrw_oficial, 'clean_town')\n",
    "stadt_nrw_oficial['clean_town'] = stadt_nrw_oficial['clean_town'].replace({'\\s{2,}': ' '}).str.strip()\n",
    "\n",
    "\n",
    "#creating the series in alphabetical order\n",
    "oficial_names = stadt_nrw_oficial['clean_town'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oficial_names.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadt_nrw_oficial['gemeinde_name_short_'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning names:\n",
    "\n",
    "stadt_nrw_oficial['gemeinde_name_short_'] = stadt_nrw_oficial['gemeinde_name_short_'].str.lower()\n",
    "\n",
    "dict_changes = {'ä': 'ae', 'ö': 'oe', 'ü': 'ue', 'β': 'ss'}\n",
    "    \n",
    "stadt_nrw_oficial.replace({'gemeinde_name_short_': dict_changes }, regex = True, inplace = True)\n",
    "\n",
    "#creating the series in alphabetical order\n",
    "oficial_names = stadt_nrw_oficial['gemeinde_name_short_'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, see if there is any town name in data_nrw_clean that is not at the oficial names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data_nrw_clean[~data_nrw_clean['result_buyer_town'].isin(oficial_names)]\n",
    "df1.result_buyer_town.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the function I created above\n",
    "print_full(oficial_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_new_changes = {'warburg-scherfede' : 'warburg', \n",
    "                    'froendenberg$' : 'froendenberg/ruhr',\n",
    "                    'schhwelm' : 'schwelm',\n",
    "                    'stadt pulheim' : 'pulheim',\n",
    "                    'emmerich$':'emmerich am rhein', \n",
    "                    'euv stadtbetrieb castrop-rauxel aoer' :'castrop-rauxel',\n",
    "                    'bergisch-gladbach' : 'bergisch gladbach',\n",
    "                    'bergsich gladbach' : 'bergisch gladbach',\n",
    "                    'hennef$' : 'hennef (sieg)',\n",
    "                    'langenfeld' : 'langenfeld (rhld.)',\n",
    "                    'leichlingen' : 'leichlingen (rhld.)',\n",
    "                    'troisdorf-sieglar' : 'troisdorf',\n",
    "                    'swisttal-miel' : 'swisttal',\n",
    "                    'bruehl-ost' : 'bruehl',\n",
    "                    'bielefdeld': 'bielefeld',\n",
    "                    'gronau$' : 'gronau (westf.)',\n",
    "                    'delbrueck-westenholz': 'delbrueck',\n",
    "                    'sundern' : 'sundern (sauerland)',\n",
    "                    'stolberg' : 'stolberg (rhld.)',\n",
    "                    'stolbeerg' : 'stolberg (rhld.)',\n",
    "                    'nettersheim-zingsheim': 'nettersheim',\n",
    "                    'uebach palenberg' : 'uebach-palenberg'}\n",
    "\n",
    "\n",
    "\n",
    "#list of municipalities that don't belong to NRW:\n",
    "rem = ['osnabrueck', 'dillenburg', 'berlin' ]\n",
    "\n",
    "#cleaning:\n",
    "data_nrw_clean.replace({'result_buyer_town': dict_new_changes }, regex = True, inplace = True)\n",
    "\n",
    "#removing:\n",
    "data_nrw_clean = data_nrw_clean[~data_nrw_clean['result_buyer_town'].isin(rem)]\n",
    "\n",
    "\n",
    "# cheking again non-matching names:\n",
    "df1 = oficial_names[~data_nrw_clean['result_buyer_town'].isin(oficial_names)]\n",
    "df1.result_buyer_town.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now all the names are the correct speling names. Let's save this clean DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nrw_clean.to_csv('cleaned_df_vergabe_nrw_jan2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nrw_clean = pd.read_csv('cleaned_df_vergabe_nrw_jan2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the DF that we are going to work from now on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 What cities are missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_with_information = data_nrw_clean['result_buyer_town'].sort_values(ascending=True)\n",
    "cities_with_information = cities_with_information.unique()\n",
    "\n",
    "df_missing = stadt_nrw_oficial[~stadt_nrw_oficial['gemeinde_name_short_'].isin(cities_with_information)]\n",
    "missing_cities = df_missing.gemeinde_name_short_.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_cities) #181\n",
    "len(oficial_names) #396\n",
    "len(cities_with_information) #216 = 215 cities + nan (empty spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "So, we have information over 215 cities and 181 cities are missing. The list of the missing cities is shown bellow. A follow-up question: does this cities have something in common ? Or are they not procuring?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " missing_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cities = pd.DataFrame(missing_cities)\n",
    "missing_cities.to_csv('missing_cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nrw_clean['result_buyer_town'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10,930 entries with no information regarding buyer town. Let's take a look on it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glimpse(stadt_nrw_oficial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glimpse(data_nrw_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the naresult_id values\n",
    "data_nrw_clean = data_nrw_clean[data_nrw_clean.result_id.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_nrw_clean.to_csv('cleaned_df_vergabe_nrw_jan2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS IS OUR DF RIGHT NOW ^^^^^^^^^^^^^^^^ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding** \n",
    "\n",
    "Mara just checked 'kalkar' and this city is publishing at their own website and at the on service.bund.de . We need to check if other municipalities are also publishing there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Is there any information regarding costs? Are the derzeitige Werten (valores correntes)?\n",
    "\n",
    "\n",
    "We have just one column that mention value ( `result_value` ) and this column has 97% of Nans considering already non-nan `result_id` . Let's see how this column looks like when we have the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('cleaned_df_vergabe_nrw_jan2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empy_value = data_nrw_clean[data_nrw_clean.result_value.notnull()]\n",
    "non_empy_value[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empy_value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 1436 values are non-nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = non_empy_value.result_value\n",
    "values.dtypes # dtype('float64')\n",
    "\n",
    "print('minimum value:', min(values), ' | max value', max(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median:\n",
    "values.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_full(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have many cases with value == 1.00 or value == 0.01... let's check unporobable values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = pd.DataFrame({'values' : values})\n",
    "df_values.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 131 entries with a 0.01 value, 77 with 1.00 value and 5 with 0.10 value.\n",
    "Let's see with values <2, which "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df1 = non_empy_value.query(\"result_value < 2\")\n",
    "df1 = data_nrw_clean[['result_value', 'result_buyer_town']]\n",
    "df1['valiable_value'] = np.where(df1['result_value'] < 2, '0', '1')\n",
    "df1.drop(\"result_value\", axis=1, inplace=True)\n",
    "#print_full(df1.value_counts())\n",
    "print_full(df1.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1436 - 131 -77 -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, it looks that have or not a value looks random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nrw_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glimpse(data_nrw_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nrw_clean.query('result_id == \"CXPNY4ZDEGR\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_nrw_clean['result_buyer_town'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_nrw_clean['result_description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nrw_clean['result_seller_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found two different documentations for this data. In none of those it specifies all the information retrieved in the data, but only the columns *created_at* and *updated_at* . All the other explanations are so far a guess based on our observation. \n",
    "\n",
    "| Column Name | Description |\n",
    "| ----------- | ----------- |\n",
    "|'Unnamed: 0',| Index created while retaining the data, only information that is not original from the Vergabe NRW|\n",
    "|'_id'| Id of input |\n",
    "|'created_at| indicates when the document was first indexed. This value is also returned via the HTTP response header Date when retrieving a single document|\n",
    "|'updated_at'|indicates when the document was *last updated*. This does not necessarily mean that the content has changed, only that it was last updated. This value is also returned via the HTTP response header Last-Modified when retrieving a single document. |\n",
    "|'result_id| Id of a valid result. It has nan values and, when its non-nan, the value is the same as the '_id' |\n",
    "|'result_title'| Short description of the object of the tender or what is that tender for |\n",
    "|'result_description'| Description of the purchases / services related to the tender. |\n",
    "|'result_procedure_type'| Assume one of the following values: 'Ex post Veröffentlichung (§ 30 Abs. 1)','Ex ante Veröffentlichung (Binnenmarktrelevanz)', 'Ex post Veröffentlichung', 'Ex post Veröffentlichung (§ 19 Abs.2)', 'Verhandlungsvergabe mit öffentlichem Teilnahmewettbewerb', 'Beschränkte Ausschreibung mit öffentlichem Teilnahmewettbewerb', 'Ex post Veröffentlichung (Binnenmarktrelevanz)', 'Ex post Veröffentlichung (§ 20 Abs.3)','Ex ante Veröffentlichung', 'Beschränkte Ausschreibung mit Teilnahmewettbewerb','Teilnahmewettbewerb', 'Ex ante Veröffentlichung (§ 19 Abs. 5)' |\n",
    "|'result_order_type'| assume values 'UVGO', 'OTHER', 'VOB', 'VOL' or empty|\n",
    "|'result_publication_date'| Publication of the tender (?) |\n",
    "|'result_cpv_codes'| CPV codes related to te tender. It can have more than one. |\n",
    "|'result_buyer_name'| Office for whom the tender is destinated, for ex: 'Polizeipräsidium Dortmund - ZA 13.1 - Zentrale Vergabestelle' |\n",
    "|'result_buyer_address'| Address of the buyer's office |\n",
    "|'result_buyer_town'| Town where the buyer's office is located|\n",
    "|'result_buyer_postal_code'| Postal code of the buyer's office |\n",
    "|'result_seller_name'| Company which owned the tender|\n",
    "|'result_seller_town'| City where the winning company is located|\n",
    "|'result_seller_country' | Country where the winning company is located |\n",
    "|'result_geo_lon' | We are not sure if this lon refers to the buyer or seller|\n",
    "|'result_geo_lat'| We are not sure if this lat refers to the buyer or seller|\n",
    "|'result_value'| Value of the tender |\n",
    "|'result_created_at'| data of creating of result (its non-nan when result_id is non-nan) | \n",
    "|'result_updated_at'| data of result update |\n",
    "|'result_buyer_country'| Country where buyer's office is located|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para converter esse script para html:\n",
    "\n",
    "\"/Users/user/Documents/Scripts e notebooks/Python notebooks/COVID19_DE_BR/Germany/2_vergabe_nrw_data_wrangling.ipynb\"\n",
    "\n",
    "\n",
    "jupyter nbconvert --to html --template hidecode \"/Users/user/Documents/Scripts e notebooks/Python notebooks/COVID19_DE_BR/Germany/2_vergabe_nrw_data_wrangling.ipynb\"\n",
    "\n",
    "jupyter nbconvert \"/Users/user/Documents/Scripts e notebooks/Python notebooks/COVID19_DE_BR/Germany/2_vergabe_nrw_data_wrangling.ipynb\"\n",
    "\n",
    " --no-input\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
